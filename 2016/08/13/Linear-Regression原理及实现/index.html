<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Linear Regression原理及实现 | 生生 - Jiaqi Fu's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Linear Regression原理及实现</h1><a id="logo" href="/.">生生 - Jiaqi Fu's Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Linear Regression原理及实现</h1><div class="post-meta">Aug 13, 2016</div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#推导"><span class="toc-number">1.</span> <span class="toc-text">推导</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#最小二乘法"><span class="toc-number">1.1.</span> <span class="toc-text">最小二乘法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#正规方程"><span class="toc-number">1.2.</span> <span class="toc-text">正规方程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#梯度下降法"><span class="toc-number">1.3.</span> <span class="toc-text">梯度下降法</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实现"><span class="toc-number">2.</span> <span class="toc-text">实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#验证"><span class="toc-number">3.</span> <span class="toc-text">验证</span></a></li></ol></div></div><div class="post-content"><h4 id="&#x63A8;&#x5BFC;"><a href="#&#x63A8;&#x5BFC;" class="headerlink" title="&#x63A8;&#x5BFC;"></a>&#x63A8;&#x5BFC;</h4><p>&#x5047;&#x8BBE;y(label)&#x4E3A;&#x5B9E;&#x6570;&#xFF0C;&#x4E14;&#x53EF;&#x4EE5;&#x7528;x(features)&#x7684;&#x7EBF;&#x6027;&#x7EC4;&#x5408;&#x8868;&#x793A;&#xFF0C;&#x5373;&#xFF1A;</p>
<p>$$<br>\mathbf{y} = \sum_{i=0}^d w_i x_i<br>$$</p>
<p>&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x8BE5;hypothesis&#x7684;&#x8868;&#x8FBE;&#x5F62;&#x5F0F;&#xFF1A;</p>
<p>$$<br>h(\mathbf{X})=\mathbf{W^T X}<br>$$</p>
<h5 id="&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;"><a href="#&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;" class="headerlink" title="&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;"></a>&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;</h5><blockquote>
<p>&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;&#x53EF;&#x4EE5;&#x4ECE;Cost/Loss function&#x89D2;&#x5EA6;&#x53BB;&#x60F3;&#xFF0C;&#x8FD9;&#x662F;&#x7EDF;&#x8BA1;&#xFF08;&#x673A;&#x5668;&#xFF09;&#x5B66;&#x4E60;&#x91CC;&#x9762;&#x4E00;&#x4E2A;&#x91CD;&#x8981;&#x6982;&#x5FF5;&#xFF0C;&#x4E00;&#x822C;&#x5EFA;&#x7ACB;&#x6A21;&#x578B;&#x5C31;&#x662F;&#x8BA9;loss function&#x6700;&#x5C0F;&#xFF0C;&#x800C;&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;&#x53EF;&#x4EE5;&#x8BA4;&#x4E3A;&#x662F; loss function = &#xFF08;y_hat -y )^2&#x7684;&#x4E00;&#x4E2A;&#x7279;&#x4F8B;&#xFF0C;&#x7C7B;&#x4F3C;&#x7684;&#x60F3;&#x5404;&#x4F4D;&#x8BF4;&#x7684;&#x8FD8;&#x53EF;&#x4EE5;&#x7528;&#x5404;&#x79CD;&#x8DDD;&#x79BB;&#x5EA6;&#x91CF;&#x6765;&#x4F5C;&#x4E3A;loss function&#x800C;&#x4E0D;&#x4EC5;&#x4EC5;&#x662F;&#x6B27;&#x6C0F;&#x8DDD;&#x79BB;&#x3002;&#x6240;&#x4EE5;loss function&#x53EF;&#x4EE5;&#x8BF4;&#x662F;&#x4E00;&#x79CD;&#x66F4;&#x4E00;&#x822C;&#x5316;&#x7684;&#x8BF4;&#x6CD5;&#x3002;</p>
</blockquote>
<p>&#x5F15;&#x81EA; <a href="https://www.zhihu.com/question/20447622/answer/36744589" target="_blank" rel="external">&#x77E5;&#x4E4E;-&#x6700;&#x5927;&#x4F3C;&#x7136;&#x4F30;&#x8BA1;&#x548C;&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;&#x600E;&#x4E48;&#x7406;&#x89E3;&#xFF1F;</a></p>
<p>&#x5BF9;&#x4E8E;Regression&#xFF0C;&#x901A;&#x5E38;&#x4F7F;&#x7528;&#x5E73;&#x65B9;&#x9519;&#x8BEF;&#xFF0C;&#x5219;&#xFF1A;</p>
<p>$$<br>err(\hat{y},y)=(\hat{y}-y)^2<br>$$</p>
<p>Cost Function&#x6216;&#x8005; Loss Function&#x4E3A;&#xFF1A;</p>
<p>$$<br>E_{in}(\mathbf{W})=\frac{1}{N} \sum_{i=1}^N (\mathbf{W^T}x_n-y_n)^2<br>$$<br>&#x6211;&#x4EEC;&#x6240;&#x8981;&#x505A;&#x7684;&#x5C31;&#x662F;&#x8BA9;&#x635F;&#x5931;&#x8FBE;&#x5230;&#x6700;&#x5C0F;&#xFF0C;&#x5373;&#x6C42;&#x89E3;&#x8FD9;&#x6837;&#x7684;&#x6700;&#x4F18;&#x5316;&#x95EE;&#x9898;&#xFF08;&#x7B80;&#x5316;&#x4E3A;&#x4E00;&#x4E2A;&#x5411;&#x91CF;&#x7684;&#x5185;&#x79EF;&#xFF09;</p>
<p>$$<br>\min \limits_{\mathbf{W}} E_{in}(\mathbf{w})=\frac{1}{N} \sum_{i=1}^N (\mathbf{W^T}x_n-y_n)^2 = \frac{1}{N} \| \mathbf{XW}-\mathbf{y} \| ^2<br>$$</p>
<p>&#x901A;&#x8FC7;&#x77E9;&#x9635;&#x7684;&#x7EBF;&#x6027;&#x4EE3;&#x6570;&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x68AF;&#x5EA6;&#x4E3A;&#xFF1A;<br>$$<br>\nabla E_{in}(\mathbf{w}) = \frac{2}{N} (\mathbf{X^T X W}-\mathbf{X^T y})<br>$$</p>
<p>&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#x6700;&#x4F18;&#x5316;&#xFF0C;&#x5206;&#x522B;&#x4E3A;<strong>&#x6B63;&#x89C4;&#x65B9;&#x7A0B;</strong>&#x548C;<strong>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;</strong>&#x3002;</p>
<h5 id="&#x6B63;&#x89C4;&#x65B9;&#x7A0B;"><a href="#&#x6B63;&#x89C4;&#x65B9;&#x7A0B;" class="headerlink" title="&#x6B63;&#x89C4;&#x65B9;&#x7A0B;"></a>&#x6B63;&#x89C4;&#x65B9;&#x7A0B;</h5><p>&#x4F7F;$\nabla E_{in}(\mathbf{w})=0$&#xFF0C;&#x53EF;&#x5F97;&#x4EE5;&#x4E0B;&#x89E3;&#xFF1A;</p>
<p>$$<br>\mathbf{W_{LIN}}=(\mathbf{X^T X})^{-1} \mathbf{X^T} \mathbf{y}<br>$$</p>
<p>&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;&#x4F7F;&#x7528;&#x7684;&#x6761;&#x4EF6;&#x662F;$\mathbf{X^T X}$&#x7684;&#x9006;&#x77E9;&#x9635;&#x5B58;&#x5728;&#xFF0C;&#x5219;$\mathbf{X}$&#x8981;&#x4E3A;&#x6EE1;&#x79E9;&#x77E9;&#x9635;&#x3002;</p>
<h5 id="&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;"><a href="#&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;" class="headerlink" title="&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;"></a>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;</h5><p>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7684;&#x7B97;&#x6CD5;&#x4E3B;&#x8981;&#x8FC7;&#x7A0B;&#xFF1A;</p>
<ol>
<li>&#x8BA1;&#x7B97; $\nabla E_{in}(\mathbf{w_t})$</li>
<li>&#x66F4;&#x65B0; $\mathbf{w_{t+1}} \longleftarrow \nabla E_{in}(\mathbf{w_t})$</li>
</ol>
<p>&#x4E0D;&#x65AD;&#x8BA1;&#x7B97;&#x4E0A;&#x4E24;&#x6B65;&#xFF0C;&#x76F4;&#x5230;$\nabla E_{in}(\mathbf{w_{t+1}})=0$&#x6216;&#x8005;&#x8DB3;&#x591F;&#x7684;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x3002;</p>
<p>&#x800C;linear regression&#x7684;&#x68AF;&#x5EA6;&#x4E0A;&#x9762;&#x5DF2;&#x7ECF;&#x5F97;&#x51FA;</p>
<p>$$<br>\nabla E_{in}(\mathbf{w}) = \frac{2}{N} (\mathbf{X^T X W}-\mathbf{X^T y})<br>$$</p>
<p>&#x5728;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x65F6;&#x5019;&#xFF0C;&#x7531;&#x4E8E;learning rate $\eta $&#x8BBE;&#x7F6E;&#x4E3A;0.1&#xFF0C;&#x76F8;&#x5BF9;&#x8F83;&#x5927;&#xFF0C;&#x5BFC;&#x81F4;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x5931;&#x8D25;&#xFF0C;&#x6700;&#x540E;&#x751A;&#x81F3;&#x4E0A;&#x5347;&#x5230;e32&#xFF01;&#x6700;&#x540E;$\eta$&#x8BBE;&#x4E3A;0.0001&#xFF0C;&#x8FED;&#x4EE3;1000&#x6B21;&#x4E4B;&#x540E;&#x5F97;&#x5230;&#x5408;&#x9002;&#x7684;&#x89E3;&#x3002;</p>
<h4 id="&#x5B9E;&#x73B0;"><a href="#&#x5B9E;&#x73B0;" class="headerlink" title="&#x5B9E;&#x73B0;"></a>&#x5B9E;&#x73B0;</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding=utf-8 -*-</span></div><div class="line"><span class="comment"># Author: fujiaqi@zju.edu.cn</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegression</span>:</span></div><div class="line"></div><div class="line">    MAX_ITER = <span class="number">1000</span></div><div class="line">    LEARNING_RATE = <span class="number">0.0001</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.X_train = np.array([])</div><div class="line">        self.X_test = np.array([])</div><div class="line">        self.y_train = np.array([])</div><div class="line">        self.y_test = np.array([])</div><div class="line">        self.w_ = np.array([])</div><div class="line">        self.mse_ = <span class="number">0.0</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X_train, y_train, gradient_descent=True)</span>:</span></div><div class="line">        self.X_train = X_train</div><div class="line">        self.y_train = y_train</div><div class="line">        <span class="keyword">if</span> gradient_descent:</div><div class="line">            w = np.array([[<span class="number">0.0</span>]] * X_train.shape[<span class="number">1</span>])</div><div class="line"></div><div class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">0</span>, self.MAX_ITER):</div><div class="line">                <span class="comment"># print &apos;iter &apos;,t</span></div><div class="line">                gradient = self.gradient_val(w)</div><div class="line">                w = w - self.LEARNING_RATE * gradient</div><div class="line">                <span class="comment"># Ein = self.cost_val(w)</span></div><div class="line">                <span class="comment"># print Ein</span></div><div class="line"></div><div class="line">            self.w_ = w</div><div class="line"></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            pseudo_inv = np.dot(np.linalg.inv(np.dot(self.X_train.T, self.X_train)), self.X_train.T)</div><div class="line">            self.w_ = np.dot(pseudo_inv, self.y_train)</div><div class="line">        <span class="keyword">return</span> self</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X_test)</span>:</span></div><div class="line">        <span class="keyword">return</span> np.dot(X_test, self.w_)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient_val</span><span class="params">(self, w)</span>:</span></div><div class="line">        tmp1 = np.dot(np.dot(self.X_train.T, self.X_train), w)</div><div class="line">        tmp2 = np.dot(self.X_train.T, self.y_train)</div><div class="line">        <span class="keyword">return</span> (tmp1 - tmp2) / self.X_train.shape[<span class="number">0</span>] * <span class="number">2</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_val</span><span class="params">(self, w)</span>:</span></div><div class="line">        tmp1 = np.dot(w.T, self.X_train.T)</div><div class="line">        tmp2 = np.dot(tmp1, self.X_train)</div><div class="line">        a = np.dot(tmp2, w)</div><div class="line">        b = <span class="number">2</span> * np.dot(np.dot(w.T, self.X_train.T), self.y_train)</div><div class="line">        c = np.dot(self.y_train.T, self.y_train)</div><div class="line">        <span class="keyword">return</span> (a - b + c) / self.X_train.shape[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<p><a href="https://github.com/umbrellabeach/linear_regression" target="_blank" rel="external">&#x5B8C;&#x6574;Github&#x4EE3;&#x7801;</a></p>
<h4 id="&#x9A8C;&#x8BC1;"><a href="#&#x9A8C;&#x8BC1;" class="headerlink" title="&#x9A8C;&#x8BC1;"></a>&#x9A8C;&#x8BC1;</h4><p>&#x4F7F;&#x7528;UCI <a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality" target="_blank" rel="external">Wine Quality</a>&#x4F5C;&#x4E3A;&#x6D4B;&#x8BD5;&#x96C6;</p>
<p>&#x5C5E;&#x6027;&#xFF1A;</p>
<p>Input variables (based on physicochemical tests): </p>
<ol>
<li>fixed acidity </li>
<li>volatile acidity </li>
<li>citric acid </li>
<li>residual sugar </li>
<li>chlorides </li>
<li>free sulfur dioxide </li>
<li>total sulfur dioxide </li>
<li>density </li>
<li>pH </li>
<li>sulphates </li>
<li>alcohol </li>
</ol>
<p>Output variable (based on sensory data): </p>
<ol>
<li>quality (score between 0 and 10)</li>
</ol>
<p>&#x4F7F;&#x7528;&#x5B9E;&#x73B0;&#x7684;&#x65B9;&#x6CD5;&#x548C;sklearn <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" target="_blank" rel="external">Linear Regression</a> API<br>&#x9A8C;&#x8BC1;&#x96C6;&#x7684;MSE&#x5206;&#x522B;&#x4E3A;</p>
<table>
<thead>
<tr>
<th>&#x65B9;&#x6CD5;</th>
<th>MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td>&#x6B63;&#x89C4;&#x6CD5;</td>
<td>0.40692278</td>
</tr>
<tr>
<td>&#x68AF;&#x5EA6;&#x6CD5;</td>
<td>0.52293456</td>
</tr>
<tr>
<td>sklearn</td>
<td>0.40630285</td>
</tr>
</tbody>
</table>
<p>&#x53C2;&#x8003;<br>1.<a href="http://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="external">Machine Learning Foundations</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://fujiaqi.com/2016/08/13/Linear-Regression原理及实现/" data-id="cj28i5yyl0009kvlnj4updu7a" class="article-share-link">Share</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/Python/">Python</a></div><div class="post-nav"><a href="/2016/09/09/Logistic-Regression逻辑回归的原理及实现/" class="pre">Logistic Regression逻辑回归的原理及实现</a><a href="/2016/07/04/Leetcode-4-Median-of-Two-Sorted-Arrays/" class="next">Leetcode 4: Median of Two Sorted Arrays</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://fujiaqi.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/Music-Computing/" style="font-size: 15px;">Music Computing</a> <a href="/tags/Algorithm/" style="font-size: 15px;">Algorithm</a> <a href="/tags/C/" style="font-size: 15px;">C++</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/05/03/Notes-in-generating-MIDI/">Notes in generating MIDI</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/18/An-introduction-to-C-RNN-GAN-Generating-Music/">An introduction to C-RNN-GAN (Generating Music)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/12/Note-Introduction-and-Applications-of-GANs-PPT/">Note: Introduction and Applications of GANs(PPT)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/06/GAN-2-Introduction-and-Interpretation-of-Paper/">GAN (2): Introduction via the Original Paper</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/05/GAN-Generative-Model-and-Discrimination-Model/">GAN (1): Generative Model and Discrimination Model</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/17/Spring-MVC-Login-Demo/">Spring MVC Login Demo</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/13/Non-Linear SVM and Kernel Function非线性支持向量机与核函数/">Non-Linear SVM and Kernel Function非线性支持向量机与核函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/12/Soft-Margin-SVM-软间隔支持向量机/">Soft-Margin SVM 软间隔支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/11/Same-Tree-Problem/">Same Tree Problem</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/02/SVM and Dual Problem 支持向量机与对偶问题/">SVM and Dual Problem 支持向量机与对偶问题</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://keefe.wang/" title="keefe's Blog" target="_blank">keefe's Blog</a><ul></ul><a href="https://github.com/umbrellabeach" title="Jiaqi Fu's Github" target="_blank">Jiaqi Fu's Github</a><ul></ul><a href="http://mypage.zju.edu.cn/en/zhangkejun" title="Kejun Zhang's Page" target="_blank">Kejun Zhang's Page</a><ul></ul><a href="http://huisblog.cn" title="huisblog" target="_blank">huisblog</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">生生 - Jiaqi Fu's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-97246531-1','auto');ga('send','pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>