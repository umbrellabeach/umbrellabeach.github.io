<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>An introduction to C-RNN-GAN (Generating Music) | 生生 - Jiaqi Fu's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">An introduction to C-RNN-GAN (Generating Music)</h1><a id="logo" href="/.">生生 - Jiaqi Fu's Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">An introduction to C-RNN-GAN (Generating Music)</h1><div class="post-meta">Apr 18, 2017</div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Background"><span class="toc-number">1.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Architecture-of-C-RNN-GAN"><span class="toc-number">2.</span> <span class="toc-text">Architecture of C-RNN-GAN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Network-Structure"><span class="toc-number">2.1.</span> <span class="toc-text">Network Structure</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Music-Representation"><span class="toc-number">2.2.</span> <span class="toc-text">Music Representation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Experiments"><span class="toc-number">3.</span> <span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Dataset"><span class="toc-number">3.1.</span> <span class="toc-text">Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameters"><span class="toc-number">3.2.</span> <span class="toc-text">Parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Freezing"><span class="toc-number">3.3.</span> <span class="toc-text">Freezing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-Matching"><span class="toc-number">3.4.</span> <span class="toc-text">Feature Matching</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation"><span class="toc-number">4.</span> <span class="toc-text">Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Rhythmics"><span class="toc-number">4.1.</span> <span class="toc-text">Rhythmics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Results"><span class="toc-number">4.2.</span> <span class="toc-text">Results</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">5.</span> <span class="toc-text">References</span></a></li></ol></div></div><div class="post-content"><p>GANs (Generative Adversarial Networks) are designed to generate realistic data. DCGAN[1] has proved to make great results in images which combines GAN with CNN. However, music and video data are time-related and time-continues. Thus, <strong>C-RNN-GAN</strong> is proposed in [2] for this objective, which works on continuous sequential data, and apply it by training it on a collection of classical music. This article introduces C-RNN-GAN from the original paper [2].</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Recurrent neural networks (RNNs) are typically used in sequential data like sentences and music. For example, modeling the <strong>conditional probability</strong> for the next token given the sequence of preceding. A network for generating sequences was proposed in [3] by computing this conditional distribution.</p>
<p>RNN has also been utilized in music computing[4-6]. And the <strong>symbolic representation</strong> is employed in these works. However, the author of [2] thinks that <strong>continuous representation</strong> works better than symbolic representation in that the former can train a highly flexible and expressive model and train whole model end-to-end. <strong>Tone length</strong>, <strong>frequency</strong>, <strong>intensity</strong>, and <strong>timing</strong> are continuous representation used in [2].</p>
<p>In the meantime, C-RNN-GAN is trained to model the <strong>joint probability</strong> ${\rm P}(X,C)$ (instead of conditional probability ${\rm P}(C|X)$).</p>
<h2 id="Architecture-of-C-RNN-GAN"><a href="#Architecture-of-C-RNN-GAN" class="headerlink" title="Architecture of C-RNN-GAN"></a>Architecture of C-RNN-GAN</h2><h3 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h3><p>The generator $G$ has <strong>depth 2 unidirectional LSTM with 350 hiddens</strong>. A random vector $z$ concatenated with the output of the previous cell is fed into the each cell in $G$. This method is common in training RNNs as language models and music.</p>
<p>The discriminator $D$ has <strong>depth 2 directional LSTM with 350 hiddens</strong>. Output from each LSTM cell in $D$ is fed into a fully connected layer with weights shared across time steps, and one sigmoid output per cell is then averaged to the final decision for the sequence.</p>
<h3 id="Music-Representation"><a href="#Music-Representation" class="headerlink" title="Music Representation"></a>Music Representation</h3><p>There are four features used in [2]:</p>
<ul>
<li>tone length</li>
<li>frequency</li>
<li>intensity</li>
<li>time spent</li>
</ul>
<p><em>Python-midi</em> tool is leveraged in processing MIDI messages. The basic event in MIDI is &#x201C;note on&#x201D; and &#x201C;note off&#x201D;. Tone length is the period during the two events. You can refer to <a href="http://www.instructables.com/id/What-is-MIDI/" target="_blank" rel="external">What is MIDI</a> and <a href="https://www.midi.org/specifications/item/table-1-summary-of-midi-message" target="_blank" rel="external">SUMMARY OF MIDI MESSAGES</a> to learn the MIDI information.</p>
<center><img src="/2017/04/18/An-introduction-to-C-RNN-GAN-Generating-Music/note.jpg" alt=""></center>

<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>The dataset contains 3697 midi files from 160 different composers of classical music which are collected from the web. Internally, all data are normalized to a tick resolution of 384 per quarter note.</p>
<h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h3><ul>
<li>learning rate: 0.1</li>
<li>L2 regularization in $G$ and $D$</li>
<li>6 epochs pretrained</li>
<li>Baseline: RNNs similar to $G$</li>
</ul>
<p>Moreover, to assess the effects on polyphony, three tones are represented, and that is named <strong>C-RNN-GAN-3</strong>.</p>
<h3 id="Freezing"><a href="#Freezing" class="headerlink" title="Freezing"></a>Freezing</h3><p>During training, $D$ can become too <strong>strong</strong>, resulting in a gradient that <strong>cannot</strong> be used to <strong>improve</strong> $G$.</p>
<p>For that reason, <strong>freezing</strong>[7] is implemented. It&#x2019;s means that $D$ stops updating whenever the training loss of $D$ is lower than <strong>70%</strong> of $G$. In the meanwhile, it does the corresponding thing when $G$ becomes too strong.</p>
<h3 id="Feature-Matching"><a href="#Feature-Matching" class="headerlink" title="Feature Matching"></a>Feature Matching</h3><p>Feature matching prevents it from over-training on $D$ which is proposed in [7]. In [7], $f(x)$ denotes activations on an intermediate layer in $D$.</p>
<p>The loss function of the generator is defines as:<br>$$<br>\begin{eqnarray}<br>L_G=|| E_{x\sim p_\mathrm{data}(x)} f(x)-E_{z\sim p_{z(x)}} f(G(z)) ||^2_2<br>\end{eqnarray}<br>$$</p>
<p>In [2], the representation $R$ from the last layer before the final logistic classification layer in $D$ is leveraged. Thus, the loss function is:<br>$$<br>\begin{eqnarray}<br>L_G=\frac{1}{m} \sum_{i=1}^m (R(x^{(i)}) - R(G(z^{(i)})))^2<br>\end{eqnarray}<br>$$</p>
<p>(note that $||X||^2_2$ is simply the sum of squares of the entries of $X$ or $\sum_r \sum_c X^2_{rc}$ according to <a href="http://ufldl.stanford.edu/wiki/index.php/Sparse_Coding:_Autoencoder_Interpretation" target="_blank" rel="external">ufldl</a>)</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><h3 id="Rhythmics"><a href="#Rhythmics" class="headerlink" title="Rhythmics"></a>Rhythmics</h3><p>In the paper, rhythmics evaluations are tested by the following aspects:</p>
<ul>
<li><strong>Polyphony</strong>. Measuring how often (at least) two tones are played simultaneously.</li>
<li><strong>Scale consistency</strong>. Counting the fraction of tones that were part of a standard scale, and reporting the number for the best matching such scale.</li>
<li><strong>Repetitions</strong>. Giving a score on how much recurrence there is in a sample.</li>
<li><strong>Tone span</strong>. Half-tone steps between the lowest and the highest tone in a sample.</li>
</ul>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><center><img src="/2017/04/18/An-introduction-to-C-RNN-GAN-Generating-Music/result.png" alt=""></center>

<p>The followed figure shows the result in [2]. The author draws a conclusion that C-RNN-GAN and C-RNN-GAN-3 get <strong>larger tone span</strong>, <strong>larger intensity span</strong>. And C-RNN-GAN-3 allows the model to output more than one tones in a song.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Radford A, Metz L, Chintala S. Unsupervised representation learning with deep convolutional generative adversarial networks[J]. arXiv preprint arXiv:1511.06434, 2015.</p>
<p>[2] Mogren O. C-RNN-GAN: Continuous recurrent neural networks with adversarial training[J]. arXiv preprint arXiv:1611.09904, 2016.</p>
<p>[3] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.</p>
<p>[4] Douglas Eck and Juergen Schmidhuber. Finding temporal structure in music: Blues improvisation with lstm recurrent networks. In Neural Networks for Signal Processing, 2002. Proceedings of the 2002 12th IEEE Workshop on, pages 747&#x2013;756. IEEE, 2002.</p>
<p>[5] Pascal Vincent Nicolas Boulanger-Lewandowski, Yoshua Bengio. Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription. In Proceedings of the 29th International Conference on Machine Learning (ICML), page 1159&#x2013;1166, 2012.</p>
<p>[6] Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence generative adversarial nets with policy gradient. arXiv preprint arXiv:1609.05473, 2016.</p>
<p>[7] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pages 2226&#x2013;2234, 2016.</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://fujiaqi.com/2017/04/18/An-introduction-to-C-RNN-GAN-Generating-Music/" data-id="cj3ccpzhg0004vclna66barpz" class="article-share-link">Share</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/GAN/">GAN</a></div><div class="post-nav"><a href="/2017/05/03/Notes-in-generating-MIDI/" class="pre">Notes in generating MIDI(PPT)</a><a href="/2017/04/12/Note-Introduction-and-Applications-of-GANs-PPT/" class="next">Note: Introduction and Applications of GANs(PPT)</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://fujiaqi.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/Music-Computing/" style="font-size: 15px;">Music Computing</a> <a href="/tags/Algorithm/" style="font-size: 15px;">Algorithm</a> <a href="/tags/C/" style="font-size: 15px;">C++</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/05/31/AI-Drummer-Demo/">AI Drummer Demo</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/03/Notes-in-generating-MIDI/">Notes in generating MIDI(PPT)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/18/An-introduction-to-C-RNN-GAN-Generating-Music/">An introduction to C-RNN-GAN (Generating Music)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/12/Note-Introduction-and-Applications-of-GANs-PPT/">Note: Introduction and Applications of GANs(PPT)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/06/GAN-2-Introduction-and-Interpretation-of-Paper/">GAN (2): Introduction via the Original Paper</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/05/GAN-Generative-Model-and-Discrimination-Model/">GAN (1): Generative Model and Discrimination Model</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/17/Spring-MVC-Login-Demo/">Spring MVC Login Demo</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/13/Non-Linear SVM and Kernel Function非线性支持向量机与核函数/">Non-Linear SVM and Kernel Function非线性支持向量机与核函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/12/Soft-Margin-SVM-软间隔支持向量机/">Soft-Margin SVM 软间隔支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/11/Same-Tree-Problem/">Same Tree Problem</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://keefe.wang/" title="keefe's Blog" target="_blank">keefe's Blog</a><ul></ul><a href="https://github.com/umbrellabeach" title="Jiaqi Fu's Github" target="_blank">Jiaqi Fu's Github</a><ul></ul><a href="http://mypage.zju.edu.cn/en/zhangkejun" title="Kejun Zhang's Page" target="_blank">Kejun Zhang's Page</a><ul></ul><a href="http://huisblog.cn" title="huisblog" target="_blank">huisblog</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">生生 - Jiaqi Fu's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-97246531-1','auto');ga('send','pageview');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>